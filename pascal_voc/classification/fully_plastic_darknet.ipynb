{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from load_pvoc_data import load_data, TRAIN_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "VALIDATION_SPLIT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img, lbl):\n",
    "    crop_img = tf.image.central_crop(img, 1)\n",
    "    resized = tf.image.resize_images(img, (256, 256))\n",
    "    norm_img = tf.image.per_image_standardization(resized)\n",
    "    \n",
    "    one_hot = tf.one_hot(lbl, 20)\n",
    "    summed = tf.reduce_sum(one_hot, axis=-2)\n",
    "    multi_hot = tf.where(\n",
    "        tf.equal(summed, 0), tf.zeros_like(summed, dtype=tf.float32), tf.ones_like(summed, dtype=tf.float32)\n",
    "    )\n",
    "    return norm_img, multi_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    train_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda:load_data(\"train\"),\n",
    "        (tf.uint8, tf.int32),\n",
    "        (tf.TensorShape([None, None, 3]), tf.TensorShape([None]))\n",
    "    ).map(preprocessing).shuffle(10000)\n",
    "    train_dataset = train_dataset.apply(tf.contrib.data.assert_element_shape((\n",
    "        [256, 256, 3],\n",
    "        [20]\n",
    "    )))\n",
    "    \n",
    "    val_length = int(VALIDATION_SPLIT * TRAIN_LENGTH)\n",
    "    val_dataset = train_dataset.take(val_length).apply(\n",
    "        tf.contrib.data.batch_and_drop_remainder(BATCH_SIZE))\n",
    "    train_dataset = train_dataset.skip(val_length).apply(\n",
    "        tf.contrib.data.batch_and_drop_remainder(BATCH_SIZE)).repeat()\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_input_fn():\n",
    "    test_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda:load_data(\"test\"),\n",
    "        (tf.uint8, tf.int32),\n",
    "        (tf.TensorShape([None, None, 3]), tf.TensorShape([None]))\n",
    "    )\n",
    "    test_dataset = test_dataset.map(preprocessing).apply(tf.contrib.data.assert_element_shape((\n",
    "        [256, 256, 3],\n",
    "        [20]\n",
    "    )))\n",
    "    return test_dataset.apply(tf.contrib.data.batch_and_drop_remainder(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(inputs, eta, scope_name, filters=32, kernel_size=3, strides=1, activation=tf.nn.relu):\n",
    "    with tf.variable_scope(scope_name):\n",
    "        w = tf.get_variable('conv_w', (kernel_size, kernel_size, int(inputs.shape[-1]), filters))\n",
    "        b = tf.get_variable('conv_b', (filters,))\n",
    "        alpha = tf.get_variable('conv_alpha', (kernel_size, kernel_size, int(inputs.shape[-1]), filters))\n",
    "        hebb = tf.get_variable('conv_hebb', (kernel_size, kernel_size, int(inputs.shape[-1]), filters),\n",
    "                               trainable=False, initializer=tf.zeros_initializer)\n",
    "    \n",
    "    x = tf.nn.conv2d(input=inputs, filter=w + tf.multiply(alpha, hebb), strides=[1, strides, strides, 1],\n",
    "                     padding='SAME') + b\n",
    "\n",
    "    # y is to be the output reshaped so as to be used as a kernel for convolution on input to get Hebbian update\n",
    "    y = tf.image.resize_images(x, [int(inputs.shape[1])] * 2)\n",
    "    y = tf.transpose(y, [1, 2, 0, 3])\n",
    "\n",
    "    # in_mod is the input padded a/c to prev. convolution\n",
    "    in_mod = tf.pad(inputs, [\n",
    "        [0, 0],\n",
    "        *([[int(np.floor((kernel_size - 1) / 2)), int(np.ceil((kernel_size - 1) / 2))]] * 2),\n",
    "        [0, 0]\n",
    "    ])\n",
    "    # in_mod is now modded so as to preserve channels and sum over mini-batch samples for Hebbian update convolution\n",
    "    in_mod = tf.transpose(in_mod, [3, 1, 2, 0])\n",
    "\n",
    "    hebb_update = tf.nn.conv2d(input=in_mod, filter=y, strides=([1] * 4), padding='VALID')\n",
    "    hebb = eta * tf.transpose(hebb_update, [1, 2, 0, 3]) + (1 - eta) * hebb\n",
    "    \n",
    "    x = tf.layers.batch_normalization(x)\n",
    "    if activation is not None:\n",
    "        x = tf.nn.relu(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(inputs, filters, scope_name, eta):\n",
    "    with tf.variable_scope(scope_name):\n",
    "        x = conv_layer(inputs, eta, scope_name='blk_layer_1', filters=filters, kernel_size=1)\n",
    "        x = conv_layer(inputs, eta, scope_name='blk_layer_2', filters=(filters * 2), activation=None)\n",
    "    return tf.nn.relu(x + inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet_block(inputs, filters, repetitions, scope_name, eta):\n",
    "    with tf.variable_scope(scope_name):\n",
    "        x = conv_layer(inputs, eta, scope_name='blk_layer_0', filters=filters, strides=2)\n",
    "        for i in range(repetitions):\n",
    "            x = residual_block(x, filters / 2, scope_name='blk_rep_' + str(i), eta=eta)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(inputs, eta, units):\n",
    "    w = tf.get_variable('dense_w', (int(inputs.shape[1]), units), initializer=tf.truncated_normal_initializer)\n",
    "    alpha = tf.get_variable('dense_alpha', (int(inputs.shape[1]), units), initializer=tf.truncated_normal_initializer)\n",
    "    hebb = tf.get_variable('dense_hebb', (int(inputs.shape[1]), units), trainable=False,\n",
    "                           initializer=tf.truncated_normal_initializer)\n",
    "    b = tf.get_variable('dense_b', (units,), initializer=tf.truncated_normal_initializer)\n",
    "        \n",
    "    y = tf.matmul(inputs, w + tf.multiply(alpha, hebb)) + b\n",
    "    hebb = eta * tf.reduce_mean(tf.matmul(tf.expand_dims(inputs, axis=-1), tf.expand_dims(y, axis=1)), axis=0) +\\\n",
    "           (1 - eta) * hebb\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet_model(features, labels, mode):  \n",
    "    features = tf.cast(features, dtype=tf.float32)\n",
    "    \n",
    "    eta = tf.get_variable('eta', (1,), initializer=tf.truncated_normal_initializer)\n",
    "    \n",
    "    x = conv_layer(features, eta, scope_name='first', filters=32)\n",
    "    x = darknet_block(x, filters=64, repetitions=1, scope_name='dark_blk_0', eta=eta)\n",
    "    x = darknet_block(x, filters=128, repetitions=2, scope_name='dark_blk_1', eta=eta)\n",
    "    x = darknet_block(x, filters=256, repetitions=8, scope_name='dark_blk_2', eta=eta)\n",
    "    x = darknet_block(x, filters=512, repetitions=8, scope_name='dark_blk_3', eta=eta)\n",
    "    x = darknet_block(x, filters=1024, repetitions=4, scope_name='dark_blk_4', eta=eta)\n",
    "    \n",
    "    x = tf.layers.average_pooling2d(x, pool_size=8, strides=8)\n",
    "    x = tf.layers.flatten(x)\n",
    "    \n",
    "    #x = tf.layers.dense(inputs=x, units=20, kernel_initializer=tf.truncated_normal_initializer())\n",
    "    x = dense_layer(x, eta, units=20)\n",
    "    \n",
    "    classes = tf.where(tf.sigmoid(x) >= 0.5, tf.ones_like(x, dtype=tf.float32), tf.zeros_like(x, dtype=tf.float32))\n",
    "    correct_prediction = tf.equal(classes, labels)\n",
    "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    acc = tf.identity(acc, name='accuracy_tensor')\n",
    "    \n",
    "    predictions = {'classes': classes, 'accuracy': acc}\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=x)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    tf.summary.scalar('accuracy', acc)\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.contrib.estimator.TowerOptimizer(tf.train.AdamOptimizer(1e-4))\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    eval_metric_ops = {'accuracy': tf.metrics.accuracy(labels=labels, predictions=classes)}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss,\n",
    "                                      eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_to_log = {'accuracy': 'accuracy_tensor'}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Replicating the `model_fn` across ['/device:GPU:0', '/device:GPU:1'].  Variables are going to be placed on ['/CPU:0'].  Consolidation device is going to be /CPU:0.\n",
      "INFO:tensorflow:Using config: {'_global_id_in_cluster': 0, '_save_checkpoints_secs': None, '_evaluation_master': '', '_num_worker_replicas': 1, '_log_step_count_steps': 10, '_service': None, '_save_summary_steps': 10, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe9a58cea20>, '_session_config': None, '_is_chief': True, '_master': '', '_num_ps_replicas': 0, '_tf_random_seed': None, '_train_distribute': None, '_task_id': 0, '_task_type': 'worker', '_model_dir': '/tmp/tmpfull', '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': 150}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function _replicate_model_fn_with_mode.<locals>.replicated_model_fn at 0x7fe9a58cdea0>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(\n",
    "    model_fn=tf.contrib.estimator.replicate_model_fn(darknet_model),\n",
    "    model_dir='/tmp/tmpfull', config=tf.estimator.RunConfig(\n",
    "        save_checkpoints_steps=150, save_summary_steps=10, log_step_count_steps=10\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/misc/rharish/resnet_venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n"
     ]
    }
   ],
   "source": [
    "validation_hook = tf.contrib.learn.monitors.replace_monitors_with_hooks(\n",
    "    [tf.contrib.learn.monitors.ValidationMonitor(\n",
    "        input_fn=lambda:train_input_fn()[1], every_n_steps=100, early_stopping_rounds=200\n",
    "    )],\n",
    "    model\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpfull/model.ckpt-501\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 502 into /tmp/tmpfull/model.ckpt.\n",
      "INFO:tensorflow:accuracy = 0.946875\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-11-01:01:35\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpfull/model.ckpt-502\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-11-01:03:29\n",
      "INFO:tensorflow:Saving dict for global step 502: accuracy = 0.92120117, global_step = 502, loss = 0.23101082\n",
      "INFO:tensorflow:Validation (step 502): global_step = 502, accuracy = 0.92120117, loss = 0.23101082\n",
      "INFO:tensorflow:step = 501, loss = 0.19905496\n",
      "INFO:tensorflow:global_step/sec: 0.0796462\n",
      "INFO:tensorflow:accuracy = 0.940625 (125.556 sec)\n",
      "INFO:tensorflow:step = 511, loss = 0.17111453 (6.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.86434\n",
      "INFO:tensorflow:accuracy = 0.928125 (5.364 sec)\n",
      "INFO:tensorflow:step = 521, loss = 0.20915262 (5.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.87725\n",
      "INFO:tensorflow:accuracy = 0.946875 (5.327 sec)\n",
      "INFO:tensorflow:step = 531, loss = 0.16541734 (5.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88047\n",
      "INFO:tensorflow:accuracy = 0.946875 (5.318 sec)\n",
      "INFO:tensorflow:step = 541, loss = 0.17886971 (5.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.87517\n",
      "INFO:tensorflow:accuracy = 0.93125 (5.333 sec)\n",
      "INFO:tensorflow:step = 551, loss = 0.17670658 (5.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.86292\n",
      "INFO:tensorflow:accuracy = 0.9625 (5.367 sec)\n",
      "INFO:tensorflow:step = 561, loss = 0.15456831 (5.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88651\n",
      "INFO:tensorflow:accuracy = 0.94375 (5.301 sec)\n",
      "INFO:tensorflow:step = 571, loss = 0.18029064 (5.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88872\n",
      "INFO:tensorflow:accuracy = 0.953125 (5.295 sec)\n",
      "INFO:tensorflow:step = 581, loss = 0.14769797 (5.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88456\n",
      "INFO:tensorflow:accuracy = 0.94375 (5.306 sec)\n",
      "INFO:tensorflow:step = 591, loss = 0.1621921 (5.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88733\n",
      "INFO:tensorflow:accuracy = 0.946875 (5.298 sec)\n",
      "INFO:tensorflow:step = 601, loss = 0.17747109 (5.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88742\n",
      "INFO:tensorflow:accuracy = 0.9625 (5.298 sec)\n",
      "INFO:tensorflow:step = 611, loss = 0.17870194 (5.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88678\n",
      "INFO:tensorflow:accuracy = 0.94375 (5.300 sec)\n",
      "INFO:tensorflow:step = 621, loss = 0.17725438 (5.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88205\n",
      "INFO:tensorflow:accuracy = 0.934375 (5.313 sec)\n",
      "INFO:tensorflow:step = 631, loss = 0.1887934 (5.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.86895\n",
      "INFO:tensorflow:accuracy = 0.940625 (5.351 sec)\n",
      "INFO:tensorflow:step = 641, loss = 0.20199741 (5.351 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 652 into /tmp/tmpfull/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.31716\n",
      "INFO:tensorflow:accuracy = 0.95 (7.595 sec)\n",
      "INFO:tensorflow:step = 651, loss = 0.18478906 (7.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.87192\n",
      "INFO:tensorflow:accuracy = 0.95 (5.340 sec)\n",
      "INFO:tensorflow:step = 661, loss = 0.15210149 (5.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.85934\n",
      "INFO:tensorflow:accuracy = 0.93125 (5.378 sec)\n",
      "INFO:tensorflow:step = 671, loss = 0.18646157 (5.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.87724\n",
      "INFO:tensorflow:accuracy = 0.95 (5.327 sec)\n",
      "INFO:tensorflow:step = 681, loss = 0.15485647 (5.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88392\n",
      "INFO:tensorflow:accuracy = 0.9375 (5.308 sec)\n",
      "INFO:tensorflow:step = 691, loss = 0.17124921 (5.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.89132\n",
      "INFO:tensorflow:accuracy = 0.95625 (5.287 sec)\n",
      "INFO:tensorflow:step = 701, loss = 0.16223596 (5.287 sec)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-11-01:05:25\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpfull/model.ckpt-652\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-11-01:07:19\n",
      "INFO:tensorflow:Saving dict for global step 652: accuracy = 0.92177737, global_step = 652, loss = 0.232546\n",
      "INFO:tensorflow:Validation (step 702): global_step = 652, accuracy = 0.92177737, loss = 0.232546\n",
      "INFO:tensorflow:Stopping. Best step: 502 with loss = 0.2310108244419098.\n",
      "INFO:tensorflow:Saving checkpoints for 703 into /tmp/tmpfull/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1925129.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7fe9aa880c88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_steps = int(((1 - VALIDATION_SPLIT) * TRAIN_LENGTH / BATCH_SIZE) * EPOCHS)\n",
    "model.train(input_fn=lambda:train_input_fn()[0], hooks=[logging_hook, validation_hook],\n",
    "            max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-11-01:07:26\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpfull/model.ckpt-703\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-11-01:08:10\n",
      "INFO:tensorflow:Saving dict for global step 703: accuracy = 0.90175784, global_step = 703, loss = 0.260796\n",
      "{'global_step': 703, 'accuracy': 0.90175784, 'loss': 0.260796}\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(input_fn=test_input_fn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
